#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
============================================================
A è‚¡çªç ´æ‰«æç³»ç»Ÿï¼ˆPivot + SQZMOM + MA200ï¼‰
ä½œè€…ï¼šyinwangï¼ˆç”± ChatGPT è¾…åŠ©ç”Ÿæˆï¼‰
åˆ›å»ºæ—¶é—´ï¼š2025-12-06
ç‰ˆæœ¬ï¼šv1.1

ã€åŠŸèƒ½ç®€ä»‹ã€‘
- æ‰«æéšæœºä¸€æ‰¹ A è‚¡è‚¡ç¥¨ï¼ˆå¯é…ç½® sampleï¼‰
- è·å–è¿‡å» N å¤©è¡Œæƒ…æ•°æ®ï¼ˆä¸éœ€è¦å¡«å†™æ—¥æœŸï¼‰
- éå®æ—¶æ•°æ®
- è‡ªåŠ¨è®¡ç®—ï¼š
    1. MA200 è¶‹åŠ¿åˆ¤æ–­
    2. LazyBear SQZMOMï¼ˆå®Œæ•´å¤åˆ» TradingViewï¼‰
    3. å‰æ–¹ pivot é˜»åŠ›ä½ï¼ˆ15/15 å¯é…ç½®ï¼‰
    4. ä¸Šç ´é˜»åŠ›ä½ + ä»Šæ—¥ä¸Šæ¶¨
    5. Squeezeâ†’Release æ¡ä»¶çš„ç¬¬ä¸€æ ¹ï¼ˆsqz_id==1ï¼‰
- æœ€ç»ˆè¾“å‡ºä¿¡å·ï¼š
    âœ“ ä¹°å…¥
    âœ“ è§‚å¯Ÿ
- è‡ªåŠ¨å¯¼å‡º CSVï¼ˆæ¯æ—¥æ–°å»ºæ–‡ä»¶å¤¹ï¼‰

ã€ä¿¡å·è¿‡æ»¤ã€‘
å¯¼å‡ºç»“æœå·²è‡ªåŠ¨æ’é™¤ ä¿¡å· = "æ— " çš„æ‰€æœ‰ä¸ªè‚¡ã€‚

ã€è¿è¡Œæ–¹æ³•ã€‘
1. å®‰è£…ä¾èµ–ï¼š
    pip install pandas numpy akshare tqdm

2. è¿è¡Œè„šæœ¬ï¼š
    python3 stock_scan.py

3. æŸ¥çœ‹è¾“å‡ºï¼š
    -> Scan_Results/YYYY-MM-DD/Pivot_Breakout_Stocks_xxxxxx.csv

ã€é€‚ç”¨äººç¾¤ã€‘
éœ€è¦æœ¬åœ°ç¦»çº¿æ‰¹é‡æ‰«æ A è‚¡çªç ´ä¿¡å·çš„é‡åŒ–ç”¨æˆ·ã€‚

============================================================
"""
import os
import json
import time
import random
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, wait, TimeoutError as ThreadingTimeoutError

import pandas as pd
import numpy as np
import akshare as ak
import asyncio
from tqdm import tqdm
from stock_query import stock_zh_a_daily_mysql

# ============================================================
# æ¨¡å— 1ï¼šé…ç½® (Configuration)
# ============================================================
CONFIG = {
    # --- æ—¶é—´èŒƒå›´ ---
    "DAYS": 365,  # æ‰«æå›æº¯å¤©æ•° (ç”¨äºè®¡ç®— MA200)

    # --- è¿‡æ»¤æ¡ä»¶ ---
    "EXCLUDE_GEM": True,  # æ’é™¤åˆ›ä¸šæ¿ï¼ˆ300ï¼‰
    "EXCLUDE_KCB": True,  # æ’é™¤ç§‘åˆ›æ¿ï¼ˆ688ï¼‰
    "EXCLUDE_BJ": True,   # æ’é™¤åŒ—äº¤æ‰€ï¼ˆ8ã€4ã€92ï¼‰
    "EXCLUDE_ST": False,  # æ’é™¤ ST/é€€
    "ADJUST": "qfq",  # å¤æƒæ–¹å¼

    # --- SQZç­–ç•¥å‚æ•° ---
    "SQZ": {
        "length": 20,
        "mult": 2.0,
        "lengthKC": 20,
        "multKC": 1.5,
        "useTrueRange": True
    },

    # --- PIVOTç­–ç•¥å‚æ•° ---
    "PIVOT_LEFT": 15,  # å·¦ä¾§ K çº¿æ•°é‡ (ç¡®è®¤é«˜ç‚¹æ‰€éœ€çš„å·¦ä¾§å¤©æ•°)
    "PIVOT_RIGHT": 15,  # å³ä¾§ K çº¿æ•°é‡ (ç¡®è®¤é«˜ç‚¹æ‰€éœ€çš„å³ä¾§å¤©æ•°)

    # --- æ–‡ä»¶è·¯å¾„/åç§° ---
    "CACHE_FILE": "stock_list_cache.json",
    "EXPORT_ENCODING": "utf-8-sig",  # CSVæ–‡ä»¶å¯¼å‡ºç¼–ç 
    "OUTPUT_FILENAME_BASE": "Buy_Stocks",  # è¾“å‡ºæ–‡ä»¶åŸºç¡€åç§°
    "OUTPUT_FOLDER_BASE": "Day_Stocks",  # ç»“æœæ–‡ä»¶å­˜æ”¾çš„æ ¹æ–‡ä»¶å¤¹

    # --- æŠ½æ ·/å¹¶å‘ ---
    "SAMPLE_SIZE": 0,  # 0 æˆ– None è¡¨ç¤ºå…¨é‡ï¼Œ>0 è¡¨ç¤ºéšæœºæŠ½æ ·æ•°é‡
    "MAX_WORKERS": 20,
    "REQUEST_TIMEOUT": 15,  # ğŸ†• **å…³é”®ï¼šakshare å•æ¬¡è¯·æ±‚æ•´ä½“è¶…æ—¶ä¿æŠ¤ï¼ˆç§’ï¼‰**

    # --- ğŸ†• æ‰‹åŠ¨è¾“å…¥ ---
    # ç¤ºä¾‹: ["600519", "000001", "300751"]ã€‚å¦‚æœéç©ºï¼Œåˆ™è·³è¿‡å…¨é‡æ‰«æã€‚
    "MANUAL_STOCK_LIST": [
                            # "000807",
                            # "000708",
                            # "002830",
                            # "301517",
                            # "000408",
                            # "600879",
                            # "600595",
                            # "601168",
                            # "002595",
                            # "301028",
                            # "002429"
                        ]
}

# ============================================================
# å·¥å…·ï¼šé‡è¯•è£…é¥°å™¨
# ============================================================
def retry(max_retries=3, delay=1):
    def decorator(func):
        def wrapper(*args, **kwargs):
            for i in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if i == max_retries - 1:
                        raise
                    time.sleep(delay)

        return wrapper

    return decorator


# ============================================================
# æ¨¡å— 2ï¼šè·å–/ç¼“å­˜ å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨ï¼ˆä¼˜å…ˆ stock_zh_a_spotï¼‰
# ============================================================
@retry(max_retries=2, delay=1)
def fetch_stock_list_safe():
    """è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨ï¼Œé‡‡ç”¨é™çº§ç­–ç•¥ä»¥æé«˜ç¨³å®šæ€§ã€‚"""
    print("[ç³»ç»Ÿ] æ­£åœ¨å°è¯•è·å–å…¨é‡è‚¡ç¥¨åˆ—è¡¨...")

    try:
        df = ak.stock_info_a_code_name()
        if not df.empty and "code" in df.columns:
            print("[ç³»ç»Ÿ] æˆåŠŸ: ä½¿ç”¨ stock_info_a_code_name æ¥å£")
            return df[["code", "name"]]
    except Exception as e:
        print(f"[è­¦å‘Š] è½»é‡æ¥å£å¤±è´¥ ({e})ï¼Œå°è¯•å¤‡ç”¨æ¥å£...")

    try:
        df = ak.stock_zh_a_spot_em()
        print("[ç³»ç»Ÿ] æˆåŠŸ: ä½¿ç”¨ stock_zh_a_spot_em æ¥å£")
        return df[["code", "name"]]
    except Exception as e:
        raise Exception(f"æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨æ¥å£å‡ä¸å¯ç”¨: {e}")


def get_stock_list_manager():
    """ç¼“å­˜ç®¡ç†å™¨ï¼šä¼˜å…ˆè¯»å–æœ¬åœ°ç¼“å­˜ï¼Œè¿‡æœŸæˆ–ä¸å­˜åœ¨åˆ™è”ç½‘æ›´æ–°ã€‚"""
    cache_file = CONFIG["CACHE_FILE"]
    today_str = datetime.now().strftime("%Y-%m-%d")

    if os.path.exists(cache_file):
        try:
            with open(cache_file, "r", encoding="utf-8") as f:
                cache = json.load(f)
            if cache.get("time") == today_str:
                print(f"[ç³»ç»Ÿ] åŠ è½½æœ¬æ—¥ç¼“å­˜ï¼Œå…± {len(cache['data'])} æ”¯è‚¡ç¥¨")
                return pd.DataFrame(cache["data"])
        except Exception:
            pass

    df = fetch_stock_list_safe()

    if not df.empty:
        with open(cache_file, "w", encoding="utf-8") as f:
            data = {
                "time": today_str,
                "data": df.to_dict(orient="records")
            }
            json.dump(data, f, ensure_ascii=False, indent=2)

    return df


def filter_stock_list(df):
    if df is None or df.empty:
        return []
    df["code"] = df["code"].astype(str)
    mask = pd.Series(False, index=df.index)
    if CONFIG["EXCLUDE_GEM"]:
        mask |= df["code"].str.startswith("300")
    if CONFIG["EXCLUDE_KCB"]:
        mask |= df["code"].str.startswith("688", "689")
    if CONFIG["EXCLUDE_BJ"]:
        mask |= df["code"].str.startswith(("8", "4", "92"))
    if CONFIG["EXCLUDE_ST"] and "name" in df.columns:
        mask |= df["name"].str.contains("ST|é€€", na=False)
    return df[~mask]["code"].tolist()


# ============================================================
# æ¨¡å— 3ï¼šæŠ€æœ¯æŒ‡æ ‡ï¼ˆSQZMOM / linreg / true_range / color / sqz_idï¼‰
# ============================================================
def tv_linreg(y, length):
    if pd.isna(y).any():
        return np.nan
    x = np.arange(length)
    y = y.values
    # é¿å… numpy.linalg.LinAlgError: Singular matrix in least squares
    if len(y) < 2:
        return np.nan

    A = np.vstack([x, np.ones(length)]).T
    try:
        m, b = np.linalg.lstsq(A, y, rcond=None)[0]
    except np.linalg.LinAlgError:
        return np.nan  # æå°‘æ•°æƒ…å†µå‡ºç°å¥‡å¼‚çŸ©é˜µ

    return m * (length - 1) + b


def true_range(df):
    prev_close = df['close'].shift(1)
    tr1 = df['high'] - df['low']
    tr2 = (df['high'] - prev_close).abs()
    tr3 = (df['low'] - prev_close).abs()
    return pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)


def get_color_cn(v, v_prev):
    if pd.isna(v) or pd.isna(v_prev):
        return None
    if v == 0:
        return "ä¸­æ€§"
    if v > 0:
        return "å¼ºå¤š" if v > v_prev else "å¼±å¤š"
    return "å¼ºç©º" if v < v_prev else "å¼±ç©º"


def add_squeeze_counter(df):
    counter = 0
    current_state = None
    sqz_id_list = []
    for status in df["sqz_status"]:
        if status in ["æŒ¤å‹", "é‡Šæ”¾"]:
            if status == current_state:
                counter += 1
            else:
                current_state = status
                counter = 1
            sqz_id_list.append(counter)
        else:
            current_state = None
            counter = 0
            sqz_id_list.append(0)
    df["sqz_id"] = sqz_id_list
    return df


def squeeze_momentum(df, length=None, mult=None, lengthKC=None, multKC=None, useTrueRange=True):
    # å…è®¸é€šè¿‡å‚æ•°è¦†ç›– CONFIG
    if length is None:
        length = CONFIG["SQZ"]["length"]
    if mult is None:
        mult = CONFIG["SQZ"]["mult"]
    if lengthKC is None:
        lengthKC = CONFIG["SQZ"]["lengthKC"]
    if multKC is None:
        multKC = CONFIG["SQZ"]["multKC"]

    close = df['close']
    high = df['high']
    low = df['low']

    # Bollinger Bands (æ³¨æ„ LazyBear ä½¿ç”¨ multKC)
    basis = close.rolling(length).mean()
    dev = multKC * close.rolling(length).std(ddof=0)
    upperBB = basis + dev
    lowerBB = basis - dev
    # ä¸ºè¾“å‡º BB å€¼ (ç”¨ % è·ç¦» basis)
    bb_width = (upperBB - lowerBB) / basis.replace(0, np.nan)

    # Keltner Channel
    ma = close.rolling(lengthKC).mean()
    r = true_range(df) if useTrueRange else (high - low)
    rangema = r.rolling(lengthKC).mean()
    upperKC = ma + rangema * multKC
    lowerKC = ma - rangema * multKC

    sqzOn = (lowerBB > lowerKC) & (upperBB < upperKC)
    sqzOff = (lowerBB < lowerKC) & (upperBB > upperKC)

    df["sqz_status"] = np.select([sqzOn, sqzOff], ["æŒ¤å‹", "é‡Šæ”¾"], default="æ— ")

    highest_h = high.rolling(lengthKC).max()
    lowest_l = low.rolling(lengthKC).min()
    avg_hl = (highest_h + lowest_l) / 2
    sma_close = close.rolling(lengthKC).mean()
    mid = (avg_hl + sma_close) / 2
    source_mid = close - mid

    # ä½¿ç”¨ apply å’Œ tv_linreg æ¥è®¡ç®— momentum
    val = source_mid.rolling(lengthKC).apply(lambda x: tv_linreg(pd.Series(x), lengthKC), raw=False)
    df["val"] = val
    df["val_prev"] = val.shift(1)
    df["val_color"] = df.apply(lambda r: get_color_cn(r["val"], r["val_prev"]), axis=1)

    df["BB_pct"] = bb_width  # ç”¨äºè¾“å‡º BB å€¼æ¯”ä¾‹ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰
    df = add_squeeze_counter(df)
    return df


# ============================================================
# æ¨¡å— 4ï¼šPivot é«˜ç‚¹ï¼ˆå‰é˜»åŠ›ä½ï¼‰
# ============================================================
def calculate_pivot_high_vectorized(df, left=None, right=None):
    if left is None:
        left = CONFIG["PIVOT_LEFT"]
    if right is None:
        right = CONFIG["PIVOT_RIGHT"]

    highs = df['high'].values
    n = len(highs)
    pivots = np.full(n, np.nan)

    # ç®€å•æ˜äº†çš„éå†ï¼ˆç›¸å¯¹å®‰å…¨ï¼‰
    for i in range(left, n - right):
        left_max = np.max(highs[i - left:i])
        right_max = np.max(highs[i + 1:i + 1 + right])
        # ä¸¥æ ¼é«˜ç‚¹ï¼šå·¦ä¾§å’Œå³ä¾§çš„æœ€é«˜ä»·éƒ½ä½äºå½“å‰é«˜ç‚¹
        if highs[i] > left_max and highs[i] > right_max:
            pivots[i] = highs[i]

    return pd.Series(pivots, index=df.index).ffill()


# ============================================================
# æ¨¡å— 5ï¼šä»Šæ—¥å®æ—¶Kè¡¥å…… + å•è‚¡ç­–ç•¥ï¼Œ
# äº¤æ˜“æ—¥æœŸï¼šå†å²+å®æ—¶ï¼Œéäº¤æ˜“æ—¥æœŸå°±æ˜¯ï¼šå†å²
# ============================================================
def append_today_realtime(symbol: str, df_daily: pd.DataFrame, period: str = "1" ):
    """
    day  open  high   low  close volume
    2025-12-05 15:00:00  7.43  7.43  7.43   7.43  22200

    date  open  high   low  close     volume      amount  outstanding_share  turnover
    2025-12-03  8.23  8.23  8.23   8.23  3681100.0  30295453.0        699623237.0  0.005262
    2025-12-04  7.82  7.82  7.82   7.82   446900.0   3494758.0        699623237.0  0.000639

    :param symbol: è‚¡ç¥¨ä»£ç 
    :param df_daily: å†å²æ•°æ®df
    :param period: å®æ—¶æ¥å£å‘¨æœŸ é»˜è®¤ 1 åˆ†é’Ÿ
    :return:
    """

    df_min = ak.stock_zh_a_minute(
        symbol=symbol,
        period=period,
        adjust=CONFIG["ADJUST"]
    )
    # åªæœ‰å®æ—¶æ•°æ®æœ€åä¸€æ¡æœ€æ–°çš„
    df_min.tail(1)

    df_min['date'] = pd.to_datetime(df_min['day']).dt.date

    for _, row in df_min.iterrows():
        new_date = row['date']
        if new_date not in pd.to_datetime(df_daily['date']).dt.date.values:
            new_row = {
                'date': new_date,
                'open': row['open'],
                'high': row['high'],
                'low': row['low'],
                'close': row['close'],
                'volume': row['volume'],
                'amount': None,  # å¦‚æœæ²¡æœ‰æ•°æ®çš„è¯ï¼Œå¯ä»¥è®¾ç½®ä¸º None æˆ–å…¶ä»–ç¼ºçœå€¼
                'outstanding_share': None,
                'turnover': None
            }

            df_daily = pd.concat([df_daily, pd.DataFrame([new_row])], ignore_index=True)

    return df_daily


def fetch_data_with_timeout(symbol, start_date, end_date, adjust, timeout):
    """
    ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œåœ¨ç‹¬ç«‹çš„çº¿ç¨‹ä¸­æ‰§è¡Œ akshare è¯·æ±‚ï¼Œå¹¶ä½¿ç”¨ Future/wait å®æ–½è¶…æ—¶ã€‚
    """

    def _fetch():
        # akåŒ…æ¥å£
        # return ak.stock_zh_a_daily(
        #     symbol=symbol,
        #     start_date=start_date,
        #     end_date=end_date,
        #     adjust=adjust
        # )

        # æœ¬åœ°mysqlæ¥å£
        return  stock_zh_a_daily_mysql(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust
        )

    # ä½¿ç”¨ä¸€ä¸ªä¸´æ—¶çš„çº¿ç¨‹æ± æ¥ç®¡ç†è¶…æ—¶ä»»åŠ¡
    with ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(_fetch)
        try:
            # ç­‰å¾… Future å®Œæˆï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
            done, not_done = wait([future], timeout=timeout)
            if future in done:
                return future.result()
            elif future in not_done:
                # è¶…æ—¶ï¼Œå–æ¶ˆä»»åŠ¡å¹¶æŠ›å‡ºå¼‚å¸¸
                future.cancel()
                raise ThreadingTimeoutError(f"è¯·æ±‚è¶…æ—¶ ({timeout}s)")
        except Exception as e:
            # æ•è·å…¶ä»–å¯èƒ½çš„å¼‚å¸¸ï¼Œå¦‚ akshare å†…éƒ¨é”™è¯¯
            raise e


# ============================================================
# æ¨¡å— 6ï¼šå•åªè‚¡ç¥¨ç­–ç•¥ï¼ˆæ•´åˆ SQZMOM + MA200 + Pivot + ä¿¡å·ï¼‰
# å…³é”®ï¼šakshare è¯·æ±‚å¢åŠ è¶…æ—¶ä¿æŠ¤
# ============================================================
def strategy_single_stock(code, start_date, end_date):
    """
    è¾“å…¥ code: '600519' / '002596' ç­‰å…­ä½å­—ç¬¦ä¸²ï¼ˆä¸å¸¦ sh/szï¼‰
    è¿”å› dict æˆ– None
    """
    symbol = f"sh{code}" if code.startswith("6") else f"sz{code}"

    try:
        # ğŸ†• ä½¿ç”¨å¸¦è¶…æ—¶ä¿æŠ¤çš„å‡½æ•°è·å–æ•°æ®
        df = fetch_data_with_timeout(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            adjust=CONFIG["ADJUST"],
            timeout=CONFIG["REQUEST_TIMEOUT"]
        )

        # éœ€è¦è‡³å°‘ 200+ å¤©çš„å†å²æ•°æ®æ‰èƒ½æ­£ç¡®è®¡ç®—æŒ‡æ ‡
        if df is None or df.empty or len(df) < 220:
            return None

        # æ·»åŠ å®æ—¶æ•°æ®ã€çœ‹æ˜¯å¦éœ€è¦ã€‘
        df = append_today_realtime(symbol, df)

        # --- æ ¸å¿ƒä¼˜åŒ–ï¼šå…ˆè®¡ç®— MA200ã€å‰é˜»åŠ›ä½å’Œæ¶¨å¹…ï¼Œåªè¦æœ‰ä¸€ä¸ªä¸æ»¡è¶³å°±ç›´æ¥æ’é™¤ ---
        current_close = float(df['close'].iloc[-1])
        prev_close = float(df['close'].iloc[-2])
        pct_chg = (current_close - prev_close) / prev_close * 100

        # MA200
        ma200_series = df['close'].rolling(200).mean()
        if ma200_series.empty or pd.isna(ma200_series.iloc[-1]):
            return None
        ma200 = ma200_series.iloc[-1]

        # Pivot (å‰é˜»åŠ›ä½)
        pivot_series = calculate_pivot_high_vectorized(df)
        if pivot_series.empty or pd.isna(pivot_series.iloc[-1]):
            return None
        last_pivot = pivot_series.iloc[-1]

        # ä¸‰ä¸ªç­–ç•¥æ¡ä»¶
        condition_trend = current_close > ma200
        condition_break = current_close > last_pivot
        condition_up = pct_chg > 0

        # ğŸŸ¢ çŸ­è·¯ä¼˜åŒ–ï¼šåªè¦æœ‰ä¸€ä¸ªæ¡ä»¶ä¸æ»¡è¶³ï¼Œç›´æ¥è¿”å› None
        if not (condition_trend and condition_break and condition_up):
            return None

        # --- ä¸‹é¢å¼€å§‹è®¡ç®— SQZMOM ---
        df = squeeze_momentum(df, useTrueRange=CONFIG["SQZ"]["useTrueRange"])
        last = df.iloc[-1]
        prev = df.iloc[-2]

        break_strength = (current_close - last_pivot) / last_pivot * 100

        # ä¿¡å·åˆ¤å®š
        signal = "æ— "

        # --- ä¹°å…¥ä¿¡å· ---
        cond_now_strong_release = (
                last.get("val_color") == "å¼ºå¤š" and
                last.get("sqz_status") == "é‡Šæ”¾" and
                int(last.get("sqz_id", 0)) == 1
        )

        cond_prev_squeeze_long = (
                prev.get("sqz_status") == "æŒ¤å‹" and
                int(prev.get("sqz_id", 0)) >= 6
        )

        if cond_now_strong_release and cond_prev_squeeze_long:
            signal = "ä¹°å…¥"

        # ä¿®å¤ï¼šç¡®ä¿ val å¯ä»¥è½¬æ¢ä¸º float
        last_val = last.get("val")

        return {
            "ä»£ç ": code,
            "ä¿¡å·": signal,
            "å½“å‰ä»·": round(current_close, 2),
            "æ¶¨å¹…%": round(pct_chg, 2),
            "MA200": round(ma200, 2),
            "å‰é˜»åŠ›ä½": round(float(last_pivot), 2),
            "çªç ´åŠ›åº¦%": round(break_strength, 2),
            "BBå€¼": None if pd.isna(last_val) else round(float(last_val), 2),
            "BBä¸­æ–‡": last.get("val_color")
        }

    except ThreadingTimeoutError:
        # æ•è·è¯·æ±‚è¶…æ—¶å¼‚å¸¸
        # print(f"[è¶…æ—¶] {code} è¯·æ±‚è¶…æ—¶ï¼Œè·³è¿‡ã€‚")
        return None

    except Exception as e:
        # æ•è· akshare è¿”å›ç©ºæ•°æ®æˆ–å…¶ä»–å¤„ç†å¼‚å¸¸
        # print(f"[é”™è¯¯] {code} å¤„ç†å¤±è´¥: {e} - ç±»å‹: {type(e).__name__}")
        return None

# ============================================================
# æ¨¡å— 7ï¼šå¹¶å‘æ‰«æ (Async Scheduler)
# ============================================================
async def main_scanner_async(stock_codes):
    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - timedelta(days=CONFIG["DAYS"])).strftime("%Y%m%d")

    print(f"\n[ä»»åŠ¡å¯åŠ¨] æ‰«æèŒƒå›´: {start_date} ~ {end_date}")
    print(f"[é…ç½®] ç›®æ ‡: {len(stock_codes)} æ”¯ | çº¿ç¨‹: {CONFIG['MAX_WORKERS']} | è¶…æ—¶: {CONFIG['REQUEST_TIMEOUT']}s")

    results = []
    loop = asyncio.get_running_loop()
    with ThreadPoolExecutor(max_workers=CONFIG["MAX_WORKERS"]) as pool:

        # ä»»åŠ¡åˆ—è¡¨ä¿æŒä¸å˜
        tasks = [
            loop.run_in_executor(pool, strategy_single_stock, code, start_date, end_date)
            for code in stock_codes
        ]

        pbar = tqdm(asyncio.as_completed(tasks), total=len(tasks), unit="stock")
        for coro in pbar:
            res = await coro
            if res:
                results.append(res)
                pbar.set_postfix({"å‘½ä¸­": len(results)})

    return results


# ============================================================
# æ¨¡å— 8ï¼šä¸»å…¥å£ï¼šæ•´åˆæµç¨‹ï¼ˆç¼“å­˜ã€è¿‡æ»¤ã€æŠ½æ ·ã€æ‰«æã€å¯¼å‡ºï¼‰
# ============================================================
def main():
    start_time = time.time()

    # 1. æ‰‹åŠ¨æ¨¡å¼ä¼˜å…ˆ
    manual_list = CONFIG["MANUAL_STOCK_LIST"]
    df_base = pd.DataFrame()

    if manual_list and isinstance(manual_list, (list, tuple)) and len(manual_list) > 0:
        target_codes = [str(c).zfill(6) for c in manual_list]
        print(f"[æ‰‹åŠ¨æ¨¡å¼] ä½¿ç”¨æ‰‹åŠ¨è¾“å…¥åˆ—è¡¨ï¼Œå…± {len(target_codes)} æ”¯è‚¡ç¥¨ã€‚")
        try:
            df_base = get_stock_list_manager()
        except Exception:
            # å¦‚æœè·å–ä¸åˆ°å…¨é‡åˆ—è¡¨ï¼Œæ‰‹åŠ¨æ¨¡å¼ä¸‹ä¹Ÿç»™å®ƒä»¬ä¸€ä¸ªé»˜è®¤å
            df_base = pd.DataFrame({"code": target_codes, "name": ["æœªçŸ¥"] * len(target_codes)})

    else:
        # å…¨å¸‚åœºè·å–å¹¶è¿‡æ»¤
        try:
            df_base = get_stock_list_manager()
        except Exception as e:
            print(f"[ç»ˆæ­¢] æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨: {e}")
            return

        valid_codes = filter_stock_list(df_base)
        if not valid_codes:
            print("[ç»ˆæ­¢] è‚¡ç¥¨åˆ—è¡¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç¼“å­˜æˆ–è¿‡æ»¤æ¡ä»¶ã€‚")
            return

        sample_size = CONFIG["SAMPLE_SIZE"]
        if isinstance(sample_size, int) and sample_size > 0 and len(valid_codes) > sample_size:
            print(f"[æŠ½æ ·æ¨¡å¼] éšæœºæŠ½å– {sample_size} æ”¯è‚¡ç¥¨è¿›è¡Œæµ‹è¯•...")
            target_codes = random.sample(valid_codes, sample_size)
        else:
            print(f"[å…¨é‡æ¨¡å¼] æ‰«ææ‰€æœ‰ {len(valid_codes)} æ”¯æœ‰æ•ˆè‚¡ç¥¨...")
            target_codes = valid_codes

    # 2. å¹¶å‘æ‰«æ
    final_data = asyncio.run(main_scanner_async(target_codes))

    # 3. ç»“æœæ•´ç†ä¸å¯¼å‡º
    if final_data:
        res_df = pd.DataFrame(final_data)

        # ğŸ†• å…³é”®ä¿®æ”¹ï¼šåªè¦ä¿¡å·ä¸º "ä¹°å…¥" çš„æ•°æ®
        res_df = res_df[res_df["ä¿¡å·"] == "ä¹°å…¥"].copy()

        if res_df.empty:
            print("\n[ç»“æœ] è¿‡æ»¤åæ²¡æœ‰å‘ç°ç¬¦åˆç­–ç•¥çš„è‚¡ç¥¨ã€‚")
            return pd.DataFrame()

        # è¡¥å…¨è‚¡ç¥¨åç§°ï¼ˆä½¿ç”¨ df_baseï¼‰
        if not df_base.empty:
            name_map = dict(zip(df_base["code"].astype(str), df_base["name"]))
            res_df.insert(1, "åç§°", res_df["ä»£ç "].map(name_map).fillna("æœªçŸ¥"))
        else:
            res_df.insert(1, "åç§°", "æœªçŸ¥")

        # æ’åºï¼šå…ˆæŒ‰ä¿¡å·ã€å†æŒ‰çªç ´åŠ›åº¦
        signal_order = {"ä¹°å…¥": 0, "è§‚å¯Ÿ": 1, "æ— ": 2}
        res_df["ä¿¡å·æ’åº"] = res_df["ä¿¡å·"].map(signal_order).fillna(3)
        res_df = res_df.sort_values(["ä¿¡å·æ’åº", "çªç ´åŠ›åº¦%"], ascending=[True, False]).drop(columns=["ä¿¡å·æ’åº"])

        # å¯¼å‡º CSV
        today_date_str = datetime.now().strftime('%Y-%m-%d')
        folder_path = os.path.join(CONFIG["OUTPUT_FOLDER_BASE"], today_date_str)
        os.makedirs(folder_path, exist_ok=True)
        timestamp = datetime.now().strftime('%H%M%S')
        file_name = f"{CONFIG['OUTPUT_FILENAME_BASE']}_{timestamp}.csv"
        full_file_path = os.path.join(folder_path, file_name)
        res_df.to_csv(full_file_path, index=False, encoding=CONFIG["EXPORT_ENCODING"])

        print("\n" + "=" * 60)
        print(f"âœ… æ‰«æå®Œæˆ | è€—æ—¶: {time.time() - start_time:.1f}s")
        print(f"ğŸ“„ ç»“æœæ–‡ä»¶å·²ä¿å­˜è‡³: {full_file_path}")
        print(f"ğŸ“ˆ å‘½ä¸­æ•°é‡: {len(res_df)}")
        print("=" * 60)
        print("--- å‘½ä¸­è‚¡ç¥¨ Top 10 ---")
        print(res_df.head(10).to_string(index=False))
        return res_df

    else:
        print("\n[ç»“æœ] æ²¡æœ‰å‘ç°ç¬¦åˆç­–ç•¥çš„è‚¡ç¥¨ã€‚")
        return pd.DataFrame()


# ============================================================
# å…¥å£
# ============================================================
if __name__ == "__main__":
    main()
import pandas as pd
import numpy as np
import asyncio
import akshare as ak
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import json
import os
import time
import random

# ============================================================
# æ¨¡å— 1ï¼šé…ç½® (Configuration)
# ============================================================
CONFIG = {
    "DAYS": 365,  # æ‰«æå›æº¯å¤©æ•° (ç”¨äºè®¡ç®— MA200)
    "SAMPLE_SIZE": 30,  # éšæœºæŠ½æ ·æ•°é‡ (None æˆ– 0 è¡¨ç¤ºæ‰«æå…¨é‡)
    "MAX_WORKERS": 32,  # å¹¶å‘çº¿ç¨‹æ•° (é’ˆå¯¹ akshare æ¥å£å»ºè®® 16-64)
    "TIMEOUT": 15,  # å•æ¬¡è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)

    # --- è¿‡æ»¤æ¡ä»¶ ---
    "EXCLUDE_GEM": True,  # æ’é™¤åˆ›ä¸šæ¿ (300)
    "EXCLUDE_KCB": True,  # æ’é™¤ç§‘åˆ›æ¿ (688)
    "EXCLUDE_BJ": True,  # æ’é™¤åŒ—äº¤æ‰€ (8, 4)
    "EXCLUDE_ST": True,  # æ’é™¤ ST/é€€å¸‚è‚¡

    # --- ç­–ç•¥å‚æ•° ---
    "PIVOT_LEFT": 15,  # å·¦ä¾§ K çº¿æ•°é‡ (ç¡®è®¤é«˜ç‚¹æ‰€éœ€çš„å·¦ä¾§å¤©æ•°)
    "PIVOT_RIGHT": 15,  # å³ä¾§ K çº¿æ•°é‡ (ç¡®è®¤é«˜ç‚¹æ‰€éœ€çš„å³ä¾§å¤©æ•°)

    # --- æ–‡ä»¶è·¯å¾„/åç§° ---
    "CACHE_FILE": "stock_list_cache.json",
    "EXPORT_ENCODING": "utf-8-sig",  # CSVæ–‡ä»¶å¯¼å‡ºç¼–ç 
    "OUTPUT_FILENAME_BASE": "Pivot_Breakout_Stocks",  # è¾“å‡ºæ–‡ä»¶åŸºç¡€åç§°
    "OUTPUT_FOLDER_BASE": "Scan_Results",  # ç»“æœæ–‡ä»¶å­˜æ”¾çš„æ ¹æ–‡ä»¶å¤¹

    # --- ğŸ†• æ‰‹åŠ¨è¾“å…¥ ---
    # ç¤ºä¾‹: ["600519", "000001", "300751"]ã€‚å¦‚æœéç©ºï¼Œåˆ™è·³è¿‡å…¨é‡æ‰«æã€‚
    "MANUAL_STOCK_LIST": [],
}


# ============================================================
# æ¨¡å— 2ï¼šå·¥å…·ä¸æ•°æ®æº (Utils & Data Source)
# ============================================================
def retry(max_retries=3, delay=1):
    """[è£…é¥°å™¨] ç½‘ç»œè¯·æ±‚è‡ªåŠ¨é‡è¯•æœºåˆ¶ã€‚"""

    def decorator(func):
        def wrapper(*args, **kwargs):
            for i in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if i == max_retries - 1:
                        raise e
                    time.sleep(delay)

        return wrapper

    return decorator


@retry(max_retries=3, delay=2)
def fetch_stock_list_safe():
    """è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨ï¼Œé‡‡ç”¨é™çº§ç­–ç•¥ä»¥æé«˜ç¨³å®šæ€§ã€‚"""
    print("[ç³»ç»Ÿ] æ­£åœ¨å°è¯•è·å–å…¨é‡è‚¡ç¥¨åˆ—è¡¨...")

    try:
        df = ak.stock_info_a_code_name()
        if not df.empty and "code" in df.columns:
            print("[ç³»ç»Ÿ] æˆåŠŸ: ä½¿ç”¨ stock_info_a_code_name æ¥å£")
            return df[["code", "name"]]
    except Exception as e:
        print(f"[è­¦å‘Š] è½»é‡æ¥å£å¤±è´¥ ({e})ï¼Œå°è¯•å¤‡ç”¨æ¥å£...")

    try:
        df = ak.stock_zh_a_spot_em()
        print("[ç³»ç»Ÿ] æˆåŠŸ: ä½¿ç”¨ stock_zh_a_spot_em æ¥å£")
        return df[["code", "name"]]
    except Exception as e:
        raise Exception(f"æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨æ¥å£å‡ä¸å¯ç”¨: {e}")


def get_stock_list_manager():
    """ç¼“å­˜ç®¡ç†å™¨ï¼šä¼˜å…ˆè¯»å–æœ¬åœ°ç¼“å­˜ï¼Œè¿‡æœŸæˆ–ä¸å­˜åœ¨åˆ™è”ç½‘æ›´æ–°ã€‚"""
    cache_file = CONFIG["CACHE_FILE"]
    today_str = datetime.now().strftime("%Y-%m-%d")

    if os.path.exists(cache_file):
        try:
            with open(cache_file, "r", encoding="utf-8") as f:
                cache = json.load(f)
            if cache.get("time") == today_str:
                print(f"[ç³»ç»Ÿ] åŠ è½½æœ¬æ—¥ç¼“å­˜ï¼Œå…± {len(cache['data'])} æ”¯è‚¡ç¥¨")
                return pd.DataFrame(cache["data"])
        except Exception:
            pass

    df = fetch_stock_list_safe()

    if not df.empty:
        with open(cache_file, "w", encoding="utf-8") as f:
            data = {
                "time": today_str,
                "data": df.to_dict(orient="records")
            }
            json.dump(data, f, ensure_ascii=False, indent=2)

    return df


def filter_stock_list(df):
    """æ ¹æ®é…ç½®æ¸…æ´—è‚¡ç¥¨åˆ—è¡¨ã€‚"""
    if df.empty: return []

    df["code"] = df["code"].astype(str)
    mask = pd.Series(False, index=df.index)

    if CONFIG["EXCLUDE_GEM"]: mask |= df["code"].str.startswith("300")
    if CONFIG["EXCLUDE_KCB"]: mask |= df["code"].str.startswith("688")
    if CONFIG["EXCLUDE_BJ"]:  mask |= df["code"].str.startswith(("8", "4"))
    if CONFIG["EXCLUDE_ST"] and "name" in df.columns:
        mask |= df["name"].str.contains("ST|é€€")

    return df[~mask]["code"].tolist()


# ============================================================
# æ¨¡å— 3ï¼šé‡åŒ–è®¡ç®—æ ¸å¿ƒ (Quant Engine)
# ============================================================
def calculate_pivot_high_vectorized(df, left, right):
    """å‘é‡åŒ–è®¡ç®— Pivot Highï¼Œä½¿ç”¨ Pandas Rolling Window å®ç°é«˜æ€§èƒ½ã€‚"""
    window = left + right + 1
    df['local_max'] = df['high'].rolling(window=window, center=True).max()
    df['is_pivot'] = (df['high'] == df['local_max'])

    if right > 0:
        df.iloc[-right:, df.columns.get_loc('is_pivot')] = False

    pivot_prices = np.where(df['is_pivot'], df['high'], np.nan)
    pivot_series = pd.Series(pivot_prices, index=df.index).ffill().shift(1)

    return pivot_series


@retry(max_retries=2, delay=1)
def strategy_single_stock(code, start_date, end_date):
    """å•åªè‚¡ç¥¨æ•°æ®è·å–å’Œç­–ç•¥è®¡ç®—ã€‚"""
    try:
        symbol = f"sh{code}" if code.startswith("6") else f"sz{code}"

        df = ak.stock_zh_a_daily(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            adjust="qfq"
        )

        if df is None or df.empty or len(df) < 200:
            return None

        ma200 = df['close'].rolling(200).mean().iloc[-1]
        pivot_series = calculate_pivot_high_vectorized(df, CONFIG["PIVOT_LEFT"], CONFIG["PIVOT_RIGHT"])
        last_pivot = pivot_series.iloc[-1]
        current_close = df['close'].iloc[-1]
        prev_close = df['close'].iloc[-2]
        pct_chg = (current_close - prev_close) / prev_close * 100

        if pd.isna(last_pivot) or pd.isna(ma200):
            return None

        condition_trend = current_close > ma200
        condition_break = current_close > last_pivot
        condition_up = pct_chg > 0

        if condition_trend and condition_break and condition_up:
            break_strength = (current_close - last_pivot) / last_pivot * 100

            return {
                "ä»£ç ": code,
                "å½“å‰ä»·": round(current_close, 2),
                "æ¶¨å¹…%": round(pct_chg, 2),
                "MA200": round(ma200, 2),
                "å‰é˜»åŠ›ä½": round(last_pivot, 2),
                "çªç ´åŠ›åº¦%": round(break_strength, 2)
            }

    except Exception:
        return None

    return None


# ============================================================
# æ¨¡å— 4ï¼šå¼‚æ­¥å¹¶å‘è°ƒåº¦ (Async Scheduler)
# ============================================================
async def main_scanner_async(stock_codes):
    """å¼‚æ­¥ä¸»ç¨‹åºï¼šè´Ÿè´£è°ƒåº¦çº¿ç¨‹æ± ï¼Œå¹¶è¡Œæ‰§è¡Œå•è‚¡ç¥¨æ‰«æä»»åŠ¡ã€‚"""
    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - timedelta(days=CONFIG["DAYS"])).strftime("%Y%m%d")

    print(f"\n[ä»»åŠ¡å¯åŠ¨] æ‰«æèŒƒå›´: {start_date} ~ {end_date}")
    print(f"[é…ç½®] ç›®æ ‡: {len(stock_codes)} æ”¯ | çº¿ç¨‹: {CONFIG['MAX_WORKERS']}")

    results = []
    loop = asyncio.get_running_loop()
    with ThreadPoolExecutor(max_workers=CONFIG["MAX_WORKERS"]) as pool:

        tasks = [
            loop.run_in_executor(pool, strategy_single_stock, code, start_date, end_date)
            for code in stock_codes
        ]

        pbar = tqdm(asyncio.as_completed(tasks), total=len(tasks), unit="stock")
        for f in pbar:
            res = await f
            if res:
                results.append(res)
                pbar.set_postfix({"å‘½ä¸­": len(results)})

    return results


# ============================================================
# æ¨¡å— 5ï¼šä¸»å…¥å£ (Entry Point)
# ============================================================
if __name__ == "__main__":
    start_time = time.time()

    # 1. ä¼˜å…ˆæ£€æŸ¥æ‰‹åŠ¨åˆ—è¡¨
    manual_list = CONFIG["MANUAL_STOCK_LIST"]
    df_base = pd.DataFrame()  # é¢„è®¾ df_base ä¸ºç©º

    if manual_list and isinstance(manual_list, list) and len(manual_list) > 0:

        target_codes = [str(c).zfill(6) for c in manual_list]  # ç¡®ä¿ä»£ç æ˜¯6ä½å­—ç¬¦ä¸²
        print(f"[æ‰‹åŠ¨æ¨¡å¼] ä½¿ç”¨æ‰‹åŠ¨è¾“å…¥åˆ—è¡¨ï¼Œå…± {len(target_codes)} æ”¯è‚¡ç¥¨ã€‚")

        # å°è¯•è·å–å…¨é‡åŸºç¡€æ•°æ®ï¼Œç”¨äºåç»­è¡¥å…¨åç§° (éå¿…é¡»ï¼Œä½†æé«˜ç”¨æˆ·ä½“éªŒ)
        try:
            df_base = get_stock_list_manager()
        except Exception:
            print("[è­¦å‘Š] æ— æ³•è·å–å…¨é‡è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ï¼Œç»“æœä¸­å°†ç¼ºå°‘è‚¡ç¥¨åç§°ã€‚")
            df_base = pd.DataFrame({"code": target_codes, "name": ["æœªçŸ¥"] * len(target_codes)})


    else:
        # 2. èµ°å…¨é‡/æŠ½æ ·é€»è¾‘

        # è·å–å¹¶è¿‡æ»¤è‚¡ç¥¨åˆ—è¡¨
        try:
            df_base = get_stock_list_manager()
        except Exception as e:
            print(f"[ç»ˆæ­¢] æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨: {e}")
            exit()

        valid_codes = filter_stock_list(df_base)

        if not valid_codes:
            print("[ç»ˆæ­¢] è‚¡ç¥¨åˆ—è¡¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç¼“å­˜æˆ–è¿‡æ»¤æ¡ä»¶ã€‚")
            exit()

        # æŠ½æ ·é€»è¾‘ (æ ¹æ® SAMPLE_SIZE é…ç½®)
        sample_size = CONFIG["SAMPLE_SIZE"]
        if isinstance(sample_size, int) and sample_size > 0 and len(valid_codes) > sample_size:
            print(f"[æŠ½æ ·æ¨¡å¼] éšæœºæŠ½å– {sample_size} æ”¯è‚¡ç¥¨è¿›è¡Œæµ‹è¯•...")
            target_codes = random.sample(valid_codes, sample_size)
        else:
            print(f"[å…¨é‡æ¨¡å¼] æ‰«ææ‰€æœ‰ {len(valid_codes)} æ”¯æœ‰æ•ˆè‚¡ç¥¨...")
            target_codes = valid_codes

    # 3. å¯åŠ¨å¼‚æ­¥æ‰«æ
    final_data = asyncio.run(main_scanner_async(target_codes))

    # 4. ç»“æœå¯¼å‡º (CSV æ–‡ä»¶å†™å…¥åˆ°æ—¥æœŸæ–‡ä»¶å¤¹)
    if final_data:
        res_df = pd.DataFrame(final_data)

        # è¡¥å…¨è‚¡ç¥¨åç§°
        name_map = dict(zip(df_base["code"], df_base["name"]))
        res_df.insert(1, "åç§°", res_df["ä»£ç "].map(name_map).fillna("æœªçŸ¥"))

        # æ’åº
        res_df = res_df.sort_values("çªç ´åŠ›åº¦%", ascending=False)

        # æ–‡ä»¶è·¯å¾„å¤„ç†
        today_date_str = datetime.now().strftime('%Y-%m-%d')

        # æ–‡ä»¶å¤¹è·¯å¾„ï¼šæ ¹ç›®å½•/æ—¥æœŸ
        folder_path = os.path.join(CONFIG["OUTPUT_FOLDER_BASE"], today_date_str)

        # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
        os.makedirs(folder_path, exist_ok=True)

        # å®Œæ•´æ–‡ä»¶åï¼šè·¯å¾„/åŸºç¡€åç§°_æ—¶é—´æˆ³.csv
        base_name = CONFIG["OUTPUT_FILENAME_BASE"]
        timestamp = datetime.now().strftime('%H%M%S')
        file_name = f"{base_name}_{timestamp}.csv"

        full_file_path = os.path.join(folder_path, file_name)

        # å†™å…¥ CSV æ–‡ä»¶
        # res_df.to_csv(full_file_path, index=False, encoding=CONFIG["EXPORT_ENCODING"])

        print("\n" + "=" * 60)
        print(f"âœ… æ‰«æå®Œæˆ | è€—æ—¶: {time.time() - start_time:.1f}s")
        print(f"ğŸ“„ ç»“æœæ–‡ä»¶å·²ä¿å­˜è‡³: {full_file_path}")
        print(f"ğŸ“ˆ å‘½ä¸­æ•°é‡: {len(res_df)}")
        print("=" * 60)
        print("--- å‘½ä¸­è‚¡ç¥¨ Top 10 ---")
        print(res_df.head(10).to_string(index=False))
    else:
        print("\n[ç»“æœ] æ²¡æœ‰å‘ç°ç¬¦åˆç­–ç•¥çš„è‚¡ç¥¨ã€‚")
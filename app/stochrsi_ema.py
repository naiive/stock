#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
============================================================
A è‚¡çªç ´æ‰«æç³»ç»Ÿï¼ˆStochRSI + EMA è¶‹åŠ¿è¿‡æ»¤ + ADX è¶‹åŠ¿å¼ºåº¦ï¼‰
ç‰ˆæœ¬ï¼šv5.5 (å¢å¼ºç‰ˆï¼šå¤šè¶‹åŠ¿å±‚çº§ + å¤š StochRSI ä¿¡å· + DI ç›¸å¯¹å¼ºåº¦)

ã€æ ¸å¿ƒç­–ç•¥ V5.5ã€‘
1. StochRSI ä¿¡å·: K çº¿ä¸Šç©¿ (20/30/40) è¶…å–æ°´å¹³ï¼Œä¸” K > D (é‡‘å‰)ã€‚
2. è¶‹åŠ¿è¿‡æ»¤: æ”¯æŒ Level 1 (C>E50>E200) å’Œ Level 2 (C>E20>E50, å¯åŠ¨è¶‹åŠ¿)ã€‚
3. ADX è¶‹åŠ¿å¼ºåº¦: ADX > 25 ä¸” +DI > -DIï¼Œå¹¶é€šè¿‡ (DI+ - DI-)/ADX è¿›è¡Œç›¸å¯¹å¼ºåº¦ç¡®è®¤ã€‚
4. æ’é™¤ä½ä»·è‚¡: è‚¡ä»·ä½äº 5.0 å…ƒçš„è‚¡ç¥¨è¢«æ’é™¤ã€‚
============================================================
"""
import os
import sys
import json
import time
import random
import math
import datetime
from concurrent.futures import ThreadPoolExecutor, wait, TimeoutError as ThreadingTimeoutError

import pandas as pd
import numpy as np
import akshare as ak
import asyncio
from tqdm import tqdm

from api.stock_query import stock_zh_a_daily_mysql

# ============================================================
# æ¨¡å— 1ï¼šé…ç½® (Configuration)
# ============================================================
CONFIG = {
    # --- ğŸ†• æ—¶é—´èŒƒå›´ ---
    "DAYS": 365,  # æ‰«æå›æº¯å¤©æ•° (ç”¨äºè®¡ç®— MA200/EMA200)

    # --- ğŸ†• è¿‡æ»¤æ¡ä»¶ (ä¿æŒä¸å˜) ---
    "EXCLUDE_GEM": True,  # æ’é™¤åˆ›ä¸šæ¿ï¼ˆ300ã€301ï¼‰
    "EXCLUDE_KCB": True,  # æ’é™¤ç§‘åˆ›æ¿ï¼ˆ688ã€689ï¼‰
    "EXCLUDE_BJ": True,  # æ’é™¤åŒ—äº¤æ‰€ï¼ˆ8ã€4ã€92ï¼‰
    "EXCLUDE_ST": False,  # æ’é™¤ ST/é€€
    "ADJUST": "qfq",  # å¤æƒæ–¹å¼

    # --- ğŸš€ ä¼˜åŒ– 1: è¶‹åŠ¿è¿‡æ»¤å‚æ•° (æ–°å¢ E20) ---
    "EMA_SETTING": {
        "lengthEMA20": 20,  # æ–°å¢ E20 å‘¨æœŸ
        "lengthEMA50": 50,
        "lengthEMA200": 200,
        # Level 2 è¶‹åŠ¿æ˜¯å¦å¯ç”¨ (C > E20 > E50 & E50 < E200)
        "LEVEL_2_TREND_ENABLED": True,
    },

    # --- ğŸš€ ä¼˜åŒ– 2: StochRSI å‚æ•° (æ”¯æŒå¤šä¿¡å·ç­‰çº§) ---
    "STOCH_RSI": {
        "lengthRSI": 14,
        "lengthStoch": 14,
        "smoothK": 3,
        "smoothD": 3,
        # ä¿¡å· 1 (æ·±åº¦å›è°ƒ/é«˜å¯é )ï¼šè¦æ±‚ K çº¿ä¸Šç©¿ 20
        "oversoldLevel1": 20,
        # ä¿¡å· 2 (ä¸­åº¦å›è°ƒ/ä¸­å¯é )ï¼šè¦æ±‚ K çº¿ä¸Šç©¿ 30
        "oversoldLevel2": 30,
        "LEVEL_2_SIGNAL_ENABLED": True,  # æ˜¯å¦å¯ç”¨ä¸­åº¦å›è°ƒä¿¡å· (Level 2)
    },

    # --- ğŸ†• ATR æ­¢ç›ˆæ­¢æŸå‚æ•° (çŸ­çº¿ä¼˜åŒ–å‚æ•°) ---
    "ATR_SETTING": {
        "lengthATR": 7,
        "stop_loss_multiplier": 2.0,  # æ­¢æŸå€æ•° M
        "take_profit_multiplier": 4.0  # æ­¢ç›ˆå€æ•°
    },

    # --- ğŸš€ ä¼˜åŒ– 3: ADX è¶‹åŠ¿å¼ºåº¦å‚æ•° (æé«˜é—¨æ§› + DIç›¸å¯¹å¼ºåº¦) ---
    "ADX_SETTING": {
        "lengthADX": 14,
        "adx_threshold": 25.0,  # æé«˜è‡³ 25.0
        "di_relative_strength": 0.15,  # DI ç›¸å¯¹å¼ºåº¦é—¨æ§› ( (DI+ - DI-) / ADX )
    },

    # --- ğŸ†• æ–‡ä»¶è·¯å¾„/åç§° (ä¿æŒä¸å˜) ---
    "CACHE_FILE": "../conf/stock_list_cache.json",
    "EXPORT_ENCODING": "utf-8-sig",  # CSVæ–‡ä»¶å¯¼å‡ºç¼–ç 
    "OUTPUT_FILENAME_BASE": "Buy_Stocks_StochRSI_EMA_ADX_ATR_V5.5",  # è¾“å‡ºæ–‡ä»¶å‰ç¼€
    "OUTPUT_FOLDER_BASE": "../stocks",  # csvè¾“å‡º æ–‡ä»¶å¤¹
    "OUTPUT_LOG": "../logs",  # LogRedirector æ—¥å¿—è¾“å‡ºæ–‡ä»¶å¤¹

    # --- ğŸ†• å¹¶å‘ (ä¿æŒä¸å˜) ---
    "MAX_WORKERS": 10,
    "REQUEST_TIMEOUT": 20,

    # --- ğŸ†• æ•°æ®æºæ§åˆ¶ (ä¿æŒä¸å˜) ---
    "USE_LOCAL_MYSQL": True,
    "USE_REAL_TIME_DATA": False,
    "SAMPLE_SIZE": 0,
    "BATCH_SIZE": 1000,
    "BATCH_INTERVAL_SEC": 1,

    # --- ğŸ†• æ‰‹åŠ¨è¾“å…¥ (ä¿æŒä¸å˜) ---
    "MANUAL_STOCK_LIST": []
}


# ============================================================
# æ¨¡å— Aï¼šPine Script æ ¸å¿ƒå¹³æ»‘å‡½æ•° (ä¿æŒä¸å˜)
# ============================================================
def pine_rma(series, length):
    """ RMA (Wilder's Smoothing) - ç”¨äºç²¾ç¡® RSI/ATR/ADX è®¡ç®— """
    if not isinstance(series, pd.Series):
        series = pd.Series(series)
    alpha = 1 / length
    return series.ewm(alpha=alpha, adjust=False).mean()


def pine_sma(series, length):
    """ Simple Moving Average (SMA) - ç”¨äºç²¾ç¡® StochRSI K/D å¹³æ»‘ """
    if not isinstance(series, pd.Series):
        series = pd.Series(series)
    return series.rolling(length).mean()


def pine_ema(series, length):
    """ EMA (Exponential Moving Average) - ç”¨äºç²¾ç¡® EMA 20/50/200 è¶‹åŠ¿è¿‡æ»¤ """
    if not isinstance(series, pd.Series):
        series = pd.Series(series)
    alpha = 2 / (length + 1)
    return series.ewm(alpha=alpha, adjust=False).mean()


# ============================================================
# æ¨¡å— Bï¼šStochRSI æ ¸å¿ƒè®¡ç®— & ATR & ADX è®¡ç®— (é€‚åº”å¤šä¿¡å·)
# ============================================================
def calculate_stoch_rsi_values(series, length_rsi, length_stoch):
    """è®¡ç®— StochRSI çš„åŸå§‹ K å€¼ (ä¿æŒä¸å˜)"""
    if not isinstance(series, pd.Series):
        series = pd.Series(series)

    delta = series.diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)

    up_avg = pine_rma(up, length_rsi)
    down_avg = pine_rma(down, length_rsi)

    rs_arr = np.where(down_avg != 0, up_avg / down_avg, np.inf)
    rsi_arr = 100 - (100 / (1 + rs_arr))

    rsi = pd.Series(rsi_arr, index=series.index)

    lowest_rsi = rsi.rolling(length_stoch).min()
    highest_rsi = rsi.rolling(length_stoch).max()

    denominator = highest_rsi - lowest_rsi

    stoch_rsi_raw = np.where(denominator != 0, (rsi - lowest_rsi) / denominator, 0)
    stoch_rsi_raw = pd.Series(stoch_rsi_raw, index=series.index) * 100

    return stoch_rsi_raw


def check_stoch_rsi_signal(k, d, oversold_level):
    """æ£€æŸ¥å•ä¸ªè¶…å–æ°´å¹³çš„ StochRSI ä¿¡å·"""
    k_crossover_level = (k.shift(1) <= oversold_level) & (k > oversold_level)
    k_gt_d = (k > d)
    return k_crossover_level.iloc[-1] & k_gt_d.iloc[-1]


def calculate_stoch_rsi_signal_and_values(df, config):
    """è®¡ç®— StochRSI K, D å€¼åŠå¤šå±‚çº§ä¹°å…¥ä¿¡å·ã€‚"""
    stoch_rsi_raw = calculate_stoch_rsi_values(df['close'], config["lengthRSI"], config["lengthStoch"])

    k = pine_sma(stoch_rsi_raw, config["smoothK"])
    d = pine_sma(k, config["smoothD"])

    k_val = k.iloc[-1]
    d_val = d.iloc[-1]

    # ä¿¡å· 1: æ·±åº¦å›è°ƒ (K çº¿ä¸Šç©¿ 20 ä¸”é‡‘å‰)
    signal_level1 = check_stoch_rsi_signal(k, d, config["oversoldLevel1"])

    # ä¿¡å· 2: ä¸­åº¦å›è°ƒ (K çº¿ä¸Šç©¿ 30 ä¸”é‡‘å‰)
    signal_level2 = False
    if config["LEVEL_2_SIGNAL_ENABLED"]:
        signal_level2 = check_stoch_rsi_signal(k, d, config["oversoldLevel2"])
        # æ’é™¤ Level 1 ä¿¡å·ï¼Œé¿å…é‡å¤è®¡æ•° (è‹¥ Level 1 æ»¡è¶³ï¼Œåˆ™ Level 2 è‡ªåŠ¨ä¸ç®—)
        if signal_level1:
            signal_level2 = False

    # è¿”å› K, D å€¼ï¼Œä»¥åŠä¸¤ä¸ªä¿¡å·ç­‰çº§
    return k_val, d_val, signal_level1, signal_level2


def calculate_atr(df, length=14):
    """ è®¡ç®— Average True Range (ATR)ï¼Œä½¿ç”¨ RMA (Wilder's Smoothing) å¹³æ»‘ã€‚"""
    df_temp = df.copy()
    high = df_temp['high']
    low = df_temp['low']
    close_prev = df_temp['close'].shift(1)

    tr1 = high - low
    tr2 = (high - close_prev).abs()
    tr3 = (low - close_prev).abs()

    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

    atr_series = pine_rma(true_range, length)

    return atr_series.iloc[-1]


def calculate_adx_values(df, length=14):
    """
    è®¡ç®— ADX, +DI (PDI) å’Œ -DI (MDI)ï¼Œä½¿ç”¨ RMA å¹³æ»‘ã€‚
    (ä¿æŒä¸å˜)
    """
    df_temp = df.copy()
    high = df_temp['high']
    low = df_temp['low']

    # Directional Movement (+DM å’Œ -DM)
    up = high - high.shift(1)
    down = low.shift(1) - low

    pdm = np.where((up > down) & (up > 0), up, 0)
    mdm = np.where((down > up) & (down > 0), down, 0)

    # è¾…åŠ©è®¡ç®— TR
    df['TR_Temp'] = pd.concat([high - low, (high - df['close'].shift(1)).abs(), (low - df['close'].shift(1)).abs()],
                              axis=1).max(axis=1)

    # å¹³æ»‘
    atr_smooth = pine_rma(df['TR_Temp'], length)
    pdm_smooth = pine_rma(pd.Series(pdm, index=df.index), length)
    mdm_smooth = pine_rma(pd.Series(mdm, index=df.index), length)

    # DI
    pdi = (pdm_smooth / atr_smooth) * 100
    mdi = (mdm_smooth / atr_smooth) * 100

    # DX
    sum_di = pdi + mdi
    dx = np.where(sum_di != 0, (pdi - mdi).abs() / sum_di * 100, 0)

    # ADX
    adx = pine_rma(pd.Series(dx, index=df.index), length)

    # è¿”å›æœ€æ–°çš„ ADX, PDI, MDI å€¼
    return adx.iloc[-1], pdi.iloc[-1], mdi.iloc[-1]


# ============================================================
# æ¨¡å— 2 - 7 (LogRedirector, äº¤æ˜“æ—¥å†, é‡è¯•è£…é¥°å™¨, è‚¡ç¥¨åˆ—è¡¨, å®æ—¶æ•°æ®)
# (ä¿æŒä¸å˜)
# ============================================================

class LogRedirector:
    MAX_BYTES = 20 * 1024 * 1024

    def __init__(self, folder="stocks"):
        self.today_str = datetime.datetime.now().strftime('%Y%m%d')
        self.log_dir = os.path.join(folder, self.today_str)
        os.makedirs(self.log_dir, exist_ok=True)
        self.terminal = sys.stdout
        self.log_file = None
        self.current_log_path = None
        self.is_active = False

    def _get_new_log_path(self):
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        log_filename = f"{timestamp}.log"
        return os.path.join(self.log_dir, log_filename)

    def _check_and_rotate(self):
        if self.log_file is None:
            self.current_log_path = self._get_new_log_path()
            self.log_file = open(self.current_log_path, 'a', encoding='utf-8')
            return True
        if os.path.getsize(self.current_log_path) > self.MAX_BYTES:
            self.log_file.write(f"\n[è½®æ¢] æ—¥å¿—è¾¾åˆ° {self.MAX_BYTES / 1024 / 1024:.0f}MB é™åˆ¶ï¼Œæ­£åœ¨åˆ‡æ¢æ–‡ä»¶...\n")
            self.log_file.close()
            self.current_log_path = self._get_new_log_path()
            self.log_file = open(self.current_log_path, 'a', encoding='utf-8')
            return True
        return False

    def __enter__(self):
        try:
            self._check_and_rotate()
            sys.stdout = self
            self.is_active = True
            self.write(
                f"\n{'=' * 70}\n[ä¼šè¯å¼€å§‹] {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n[æ—¥å¿—æ–‡ä»¶] {self.current_log_path}\n{'=' * 70}\n")
            return self
        except Exception as e:
            print(f"[é”™è¯¯] æ—¥å¿—ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}", file=self.terminal)
            sys.stdout = self.terminal
            return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.is_active:
            self.write(
                f"\n{'=' * 70}\n[ä¼šè¯ç»“æŸ] {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n{'=' * 70}\n")
            sys.stdout = self.terminal
            if self.log_file:
                self.log_file.close()
            print(f"æ—¥å¿—æ–‡ä»¶å·²ä¿å­˜è‡³: {self.current_log_path}")

    def write(self, message):
        self.terminal.write(message)
        self.terminal.flush()
        if self.log_file:
            self._check_and_rotate()
            if not message.startswith('\r'):
                self.log_file.write(f"[{datetime.datetime.now().strftime('%H:%M:%S')}] {message}")
            else:
                self.log_file.write(message)
            self.log_file.flush()

    def flush(self):
        self.terminal.flush()
        if self.log_file: self.log_file.flush()


_TRADE_CALENDAR = set()


def is_trade_day(date_obj): return date_obj in _TRADE_CALENDAR


def load_trade_calendar():
    global _TRADE_CALENDAR
    _TRADE_CALENDAR.clear()
    try:
        print("[ç³»ç»Ÿ] æ­£åœ¨åŠ è½½äº¤æ˜“æ—¥å†...")
        calendar_df = ak.tool_trade_date_hist_sina()
        if calendar_df.empty or 'trade_date' not in calendar_df.columns: raise ValueError(
            "äº¤æ˜“æ—¥å†æ•°æ®ç»“æ„ä¸æ­£ç¡®æˆ–ä¸ºç©ºã€‚")
        trade_dates = calendar_df['trade_date'].tolist()
        for d in trade_dates:
            if isinstance(d, str):
                date_obj = datetime.datetime.strptime(d, '%Y%m%d').date()
            elif isinstance(d, datetime.datetime):
                date_obj = d.date()
            elif isinstance(d, datetime.date):
                date_obj = d
            else:
                continue
            _TRADE_CALENDAR.add(date_obj)
        print(f"[ç³»ç»Ÿ] äº¤æ˜“æ—¥å†åŠ è½½å®Œæˆï¼Œå…± {len(_TRADE_CALENDAR)} ä¸ªäº¤æ˜“æ—¥ã€‚")
    except Exception as e:
        print(f"[è­¦å‘Š] æ— æ³•åŠ è½½äº¤æ˜“æ—¥å†ï¼Œå®æ—¶æ•°æ®è¿½åŠ åŠŸèƒ½å¯èƒ½å¤±æ•ˆ: {e}")


def retry(max_retries=10, delay=15):
    def decorator(func):
        def wrapper(*args, **kwargs):
            for i in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if i == max_retries - 1: raise
                    print(f"[è­¦å‘Š] {func.__name__} å¤±è´¥ ({type(e).__name__})ï¼Œ{delay}s åé‡è¯•...")
                    time.sleep(delay)

        return wrapper

    return decorator


@retry(max_retries=2, delay=1)
def fetch_stock_list_safe():
    print("[ç³»ç»Ÿ] æ­£åœ¨å°è¯•è·å–å…¨é‡è‚¡ç¥¨åˆ—è¡¨...")
    try:
        df = ak.stock_info_a_code_name()
        if not df.empty and "code" in df.columns:
            print("[ç³»ç»Ÿ] æˆåŠŸ: ä½¿ç”¨ stock_info_a_code_name æ¥å£")
            return df[["code", "name"]]
    except Exception as e:
        print(f"[è­¦å‘Š] è½»é‡æ¥å£å¤±è´¥ ({e})ï¼Œå°è¯•å¤‡ç”¨æ¥å£...")
    try:
        df = ak.stock_zh_a_spot_em()
        print("[ç³»ç»Ÿ] æˆåŠŸ: ä½¿ç”¨ stock_zh_a_spot_em æ¥å£")
        if 'ä»£ç ' in df.columns: df = df.rename(columns={'ä»£ç ': 'code', 'åç§°': 'name'})
        return df[["code", "name"]]
    except Exception as e:
        raise Exception(f"æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨æ¥å£å‡ä¸å¯ç”¨: {e}")


def get_stock_list_manager():
    cache_file = CONFIG["CACHE_FILE"]
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    if os.path.exists(cache_file):
        try:
            with open(cache_file, "r", encoding="utf-8") as f:
                cache = json.load(f)
            if cache.get("time") == today_str:
                print(f"[ç³»ç»Ÿ] åŠ è½½æœ¬æ—¥ç¼“å­˜ï¼Œå…± {len(cache['data'])} æ”¯è‚¡ç¥¨")
                return pd.DataFrame(cache["data"])
        except Exception:
            pass
    df = fetch_stock_list_safe()
    if not df.empty:
        with open(cache_file, "w", encoding="utf-8") as f:
            data = {"time": today_str, "data": df.to_dict(orient="records")}
            json.dump(data, f, ensure_ascii=False, indent=2)
    return df


def filter_stock_list(df):
    if df is None or df.empty: return []
    df["code"] = df["code"].astype(str).str.zfill(6)
    mask = pd.Series(False, index=df.index)
    if CONFIG["EXCLUDE_GEM"]: mask |= df["code"].str.startswith(("300", "301"))
    if CONFIG["EXCLUDE_KCB"]: mask |= df["code"].str.startswith(("688", "689"))
    if CONFIG["EXCLUDE_BJ"]: mask |= df["code"].str.startswith(("8", "4", "92"))
    if CONFIG["EXCLUDE_ST"] and "name" in df.columns: mask |= df["name"].str.contains("ST|é€€", na=False)
    return df[~mask]["code"].tolist()


@retry(max_retries=10, delay=15)
def fetch_realtime_snapshot():
    print("[ç³»ç»Ÿ] æ­£åœ¨å°è¯•è·å–å…¨å¸‚åœºå®æ—¶è¡Œæƒ…å¿«ç…§...")
    try:
        df = ak.stock_zh_a_spot()
    except Exception as e:
        print(f"[é”™è¯¯] è·å–å®æ—¶å¿«ç…§å¤±è´¥: {e}")
        return pd.DataFrame()
    df = df.rename(
        columns={'ä»£ç ': 'code', 'æœ€æ–°ä»·': 'close', 'æˆäº¤é‡': 'volume', 'ä»Šå¼€': 'open', 'æœ€é«˜': 'high', 'æœ€ä½': 'low',
                 'æˆäº¤é¢': 'amount', 'é‡‘é¢': 'amount', })
    if 'code' in df.columns:
        df['code'] = df['code'].astype(str).str.replace(r'\D', '', regex=True)
        df['code'] = df['code'].str.zfill(6)
    else:
        return pd.DataFrame()
    required_cols = ['code', 'open', 'high', 'low', 'close', 'volume', 'amount']
    for col in required_cols:
        if col not in df.columns: df[col] = np.nan
    df = df[required_cols]
    numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
    for col in numeric_cols: df[col] = pd.to_numeric(df[col], errors='coerce')
    print(f"[ç³»ç»Ÿ] æˆåŠŸè·å– {len(df)} æ¡å®æ—¶å¿«ç…§æ•°æ®ã€‚")
    return df


def append_today_realtime_snapshot(code: str, df_daily: pd.DataFrame, df_spot: pd.DataFrame) -> pd.DataFrame:
    latest_date = datetime.datetime.now().date()
    if not is_trade_day(latest_date): return df_daily
    spot_row = df_spot[df_spot['code'] == code]
    if spot_row.empty: return df_daily
    latest_data = spot_row.iloc[0]
    if not df_daily.empty:
        df_daily_dates = pd.to_datetime(df_daily['date']).dt.date
        last_history_date = df_daily_dates.iloc[-1]
        if last_history_date == latest_date: return df_daily
        if last_history_date > latest_date: return df_daily
    new_row_data = {
        'date': latest_date, 'open': latest_data.get('open'), 'high': latest_data.get('high'),
        'low': latest_data.get('low'), 'close': latest_data.get('close'),
        'volume': latest_data.get('volume'), 'amount': latest_data.get('amount'),
        'outstanding_share': None, 'turnover': None, 'adjust': CONFIG.get("ADJUST", ""), 'code': code,
    }
    try:
        df_new_day = pd.DataFrame([new_row_data], columns=df_daily.columns)
    except ValueError:
        df_new_day = pd.DataFrame([new_row_data])
    df_final = pd.concat([df_daily, df_new_day], ignore_index=True)
    return df_final


def fetch_data_with_timeout(symbol, start_date, end_date, adjust, timeout):
    def _fetch():
        if CONFIG["USE_LOCAL_MYSQL"]:
            try:
                return stock_zh_a_daily_mysql(symbol=symbol, start_date=start_date, end_date=end_date, adjust=adjust)
            except NameError:
                print(f"\n[é”™è¯¯] {symbol} å°è¯•ä½¿ç”¨ MySQL æ¥å£å¤±è´¥ (NameError)ï¼Œè‡ªåŠ¨é™çº§åˆ° AkShareã€‚\n")
            except Exception as e:
                print(f"\n[é”™è¯¯] {symbol} å°è¯•ä½¿ç”¨ MySQL æ¥å£å¤±è´¥ ({type(e).__name__})ï¼Œè‡ªåŠ¨é™çº§åˆ° AkShareã€‚\n")
        return ak.stock_zh_a_daily(symbol=symbol, start_date=start_date, end_date=end_date, adjust=adjust)

    with ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(_fetch)
        try:
            done, not_done = wait([future], timeout=timeout)
            if future in done:
                return future.result()
            elif future in not_done:
                future.cancel()
                raise ThreadingTimeoutError(f"è¯·æ±‚è¶…æ—¶ ({timeout}s)")
        except Exception as e:
            raise e


# ============================================================
# æ¨¡å— 8ï¼šå•åªè‚¡ç¥¨ç­–ç•¥ (V5.5 æ ¸å¿ƒé€»è¾‘)
# ============================================================
def strategy_single_stock(code, start_date, end_date, df_spot):
    symbol = f"sh{code}" if code.startswith("6") else f"sz{code}"

    try:
        df = fetch_data_with_timeout(symbol=symbol, start_date=start_date, end_date=end_date, adjust=CONFIG["ADJUST"],
                                     timeout=CONFIG["REQUEST_TIMEOUT"])

        # æ£€æŸ¥æ•°æ®é•¿åº¦
        if df is None or df.empty or len(df) < CONFIG["EMA_SETTING"]["lengthEMA200"] + 20: return None  # é¢„ç•™ç©ºé—´

        # å®æ—¶æ•°æ®æ‹¼æ¥
        if CONFIG["USE_REAL_TIME_DATA"]:
            df = append_today_realtime_snapshot(code, df, df_spot)

        if len(df) < CONFIG["EMA_SETTING"]["lengthEMA200"]: return None

        df['date'] = pd.to_datetime(df['date']).dt.date
        df = df.sort_values('date').reset_index(drop=True)
        current_close = df['close'].iloc[-1]
        current_low = df['low'].iloc[-1]

        # --- ä»·æ ¼è¿‡æ»¤ (ä½äº 5.0 å…ƒç›´æ¥æ’é™¤) ---
        if current_close < 5.0: return None

        # --- ç­–ç•¥æ ¸å¿ƒè®¡ç®— ---

        # 1. StochRSI ä¿¡å· (å¤šå±‚çº§)
        stoch_config = CONFIG["STOCH_RSI"]
        k_val, d_val, sig_level1, sig_level2 = calculate_stoch_rsi_signal_and_values(df, stoch_config)

        # å¿…é¡»è‡³å°‘æ»¡è¶³ä¸€ä¸ª StochRSI ä¿¡å·
        if not (sig_level1 or sig_level2): return None

        # 2. EMA è¶‹åŠ¿è¿‡æ»¤ (å¤šå±‚çº§)
        ema_config = CONFIG["EMA_SETTING"]
        ema20 = pine_ema(df['close'], ema_config["lengthEMA20"]).iloc[-1]
        ema50 = pine_ema(df['close'], ema_config["lengthEMA50"]).iloc[-1]
        ema200 = pine_ema(df['close'], ema_config["lengthEMA200"]).iloc[-1]

        # å¼ºåŠ¿è¶‹åŠ¿ (Level 1): C > E50 > E200
        trend_level1 = (current_close > ema50) and (ema50 > ema200)

        # å¯åŠ¨è¶‹åŠ¿ (Level 2): C > E20 > E50, E50 < E200
        trend_level2 = False
        if ema_config["LEVEL_2_TREND_ENABLED"]:
            trend_level2 = (current_close > ema20) and (ema20 > ema50) and (ema50 < ema200)

        # å¿…é¡»è‡³å°‘æ»¡è¶³ä¸€ä¸ªè¶‹åŠ¿è¿‡æ»¤
        if not (trend_level1 or trend_level2): return None

        # ç¡®å®šæœ€ç»ˆçš„ä¿¡å·æè¿°
        if trend_level1 and sig_level1:
            signal_desc = "L1/L1 (å¼ºåŠ¿/æ·±å›è°ƒ)"
            trend_desc = "Level 1: C>E50>E200"
        elif trend_level1 and sig_level2:
            signal_desc = "L1/L2 (å¼ºåŠ¿/æµ…å›è°ƒ)"
            trend_desc = "Level 1: C>E50>E200"
        elif trend_level2 and (sig_level1 or sig_level2):
            signal_desc = "L2/L(1/2) (å¯åŠ¨/å›è°ƒ)"
            trend_desc = "Level 2: C>E20>E50"
        else:
            # ç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼Œä½†ä½œä¸ºä¿åº•
            return None

        # 3. ADX è¶‹åŠ¿å¼ºåº¦è¿‡æ»¤ (ADX > 25.0 ä¸” DI ç›¸å¯¹å¼ºåº¦)
        adx_config = CONFIG["ADX_SETTING"]
        adx_val, pdi_val, mdi_val = calculate_adx_values(df, length=adx_config["lengthADX"])

        # ADX è¶‹åŠ¿å¼ºåº¦ (ADX > é—¨æ§›) ä¸” æ–¹å‘æ­£ç¡® (+DI > -DI)
        adx_direction_filter = (adx_val > adx_config["adx_threshold"]) and (pdi_val > mdi_val)

        # DI ç›¸å¯¹å¼ºåº¦ (DI+ - DI-) / ADX > 0.15
        sum_di = pdi_val + mdi_val
        di_relative_strength = (pdi_val - mdi_val) / adx_val if adx_val != 0 else 0
        adx_relative_filter = (adx_val > 15) and (di_relative_strength >= adx_config["di_relative_strength"])

        # ADX æœ€ç»ˆè¿‡æ»¤ï¼šåŒæ—¶æ»¡è¶³ ADX é—¨æ§›å’Œ DI ç›¸å¯¹å¼ºåº¦ï¼ˆæˆ– ADX ä¿¡å·æå¼ºï¼‰
        adx_filter = adx_direction_filter and adx_relative_filter

        adx_signal = 'Buy' if adx_filter else 'å¾…ç¡®è®¤'  # æ–°å¢å¾…ç¡®è®¤çŠ¶æ€

        if not adx_filter: return None

        # 4. ATR åŠæ­¢ç›ˆæ­¢æŸä½
        atr_length = CONFIG["ATR_SETTING"]["lengthATR"]
        sl_mult = CONFIG["ATR_SETTING"]["stop_loss_multiplier"]
        tp_mult = CONFIG["ATR_SETTING"]["take_profit_multiplier"]

        current_atr = calculate_atr(df, length=atr_length)

        stop_loss_price = current_low - (sl_mult * current_atr)
        take_profit_price = current_close + (tp_mult * current_atr)

        # --- æ»¡è¶³æ‰€æœ‰æ¡ä»¶ï¼Œæ„å»ºè¿”å›ç»“æœ ---

        pct_chg = (current_close / df['close'].iloc[-2] - 1) * 100 if len(df) >= 2 else 0

        return {
            "ä»£ç ": code,
            "æ—¥æœŸ": df['date'].iloc[-1].strftime('%Y-%m-%d'),
            "ä¿¡å·ç­‰çº§": signal_desc,  # ğŸ†• ä¿¡å·ç­‰çº§
            "å½“å‰ä»·": round(current_close, 2),
            "æ¶¨å¹…%": round(pct_chg, 2),
            "StochK": round(float(k_val), 2),
            "StochD": round(float(d_val), 2),
            "EMA20": round(float(ema20), 2),  # ğŸ†• EMA20
            "EMA50": round(float(ema50), 2),
            "EMA200": round(float(ema200), 2),
            "ADX": round(float(adx_val), 2),
            "DI+": round(float(pdi_val), 2),
            "DI-": round(float(mdi_val), 2),
            "DIç›¸å¯¹å¼º": round(float(di_relative_strength), 2),  # ğŸ†• DI ç›¸å¯¹å¼ºåº¦
            "ADXä¿¡å·": adx_signal,
            "ATR": round(float(current_atr), 3),
            "æ­¢æŸä»·": round(stop_loss_price, 2),
            "æ­¢ç›ˆä»·": round(take_profit_price, 2),
            "è¶‹åŠ¿è¿‡æ»¤": trend_desc,  # ğŸ†• è¶‹åŠ¿æè¿°
        }

    except ThreadingTimeoutError:
        print(f"[è¶…æ—¶] {code} è¯·æ±‚å†å²æ•°æ®è¶…æ—¶ï¼Œè·³è¿‡ã€‚")
        return None

    except Exception as e:
        print(f"[é”™è¯¯] {code} å¤„ç†å¤±è´¥: {type(e).__name__}: {e}")
        return None


# ============================================================
# æ¨¡å— 9 & 10ï¼šå¹¶å‘æ‰«æ & ä¸»å…¥å£ (æ›´æ–°è¾“å‡ºåˆ—)
# ============================================================
async def main_scanner_async(stock_codes, df_spot):
    end_date = datetime.datetime.now().strftime("%Y%m%d")
    start_date = (datetime.datetime.now() - datetime.timedelta(days=CONFIG["DAYS"])).strftime("%Y%m%d")
    results = []
    loop = asyncio.get_running_loop()
    with ThreadPoolExecutor(max_workers=CONFIG["MAX_WORKERS"]) as pool:
        tasks = [
            loop.run_in_executor(pool, strategy_single_stock, code, start_date, end_date, df_spot)
            for code in stock_codes
        ]
        pbar = tqdm(asyncio.as_completed(tasks), total=len(tasks), unit="stock")
        for coro in pbar:
            res = await coro
            if res:
                results.append(res)
                pbar.set_postfix({"å‘½ä¸­": len(results)})
    return results


async def batch_scan_manager_async(target_codes, df_spot):
    all_results = []
    batch_size = CONFIG.get("BATCH_SIZE", 500)
    interval = CONFIG.get("BATCH_INTERVAL_SEC", 2)
    total_stocks = len(target_codes)
    num_batches = math.ceil(total_stocks / batch_size)

    print(f"\n[è°ƒåº¦å™¨] æ€»è®¡ {total_stocks} æ”¯è‚¡ç¥¨ï¼Œå°†åˆ†ä¸º {num_batches} æ‰¹æ¬¡ ({batch_size} æ”¯/æ‰¹)ã€‚")
    for i in range(num_batches):
        start_index = i * batch_size
        end_index = min((i + 1) * batch_size, total_stocks)
        batch_codes = target_codes[start_index:end_index]
        print("\n" + "=" * 60)
        print(f"--- ğŸš€ å¼€å§‹å¤„ç†æ‰¹æ¬¡ {i + 1}/{num_batches} ({len(batch_codes)} æ”¯) ---")
        batch_results = await main_scanner_async(batch_codes, df_spot)
        all_results.extend(batch_results)
        if i < num_batches - 1:
            print(f"--- ğŸ˜´ æ‰¹æ¬¡ {i + 1} å®Œæˆï¼Œå½“å‰æ€»å‘½ä¸­: {len(all_results)}ï¼Œä¼‘æ¯ {interval} ç§’... ---")
            time.sleep(interval)
        else:
            print("--- ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆã€‚---")
    return all_results


def main():
    start_time = time.time()
    if CONFIG["USE_REAL_TIME_DATA"]: load_trade_calendar()

    with LogRedirector(folder=CONFIG['OUTPUT_LOG']) as log_redirector:
        end_date = datetime.datetime.now().strftime("%Y%m%d")
        start_date = (datetime.datetime.now() - datetime.timedelta(days=CONFIG["DAYS"])).strftime("%Y%m%d")
        print(f"\n[ä»»åŠ¡å¯åŠ¨] æ‰«æèŒƒå›´: {start_date} ~ {end_date}")
        print(f"[é…ç½®] ç›®æ ‡çº¿ç¨‹: {CONFIG['MAX_WORKERS']} | è¶…æ—¶: {CONFIG['REQUEST_TIMEOUT']}s")
        print(
            f"[é…ç½®] è¶‹åŠ¿è¿‡æ»¤: L1 (C>E50>E200), L2 (C>E20>E50) å¯ç”¨={CONFIG['EMA_SETTING']['LEVEL_2_TREND_ENABLED']}")
        print(
            f"[é…ç½®] StochRSI: L1 (K>20), L2 (K>30) å¯ç”¨={CONFIG['STOCH_RSI']['LEVEL_2_SIGNAL_ENABLED']}")
        print(
            f"[é…ç½®] ADXè¿‡æ»¤: é—¨æ§›={CONFIG['ADX_SETTING']['adx_threshold']}, DIç›¸å¯¹å¼ºåº¦={CONFIG['ADX_SETTING']['di_relative_strength']}")

        df_spot = pd.DataFrame()
        if CONFIG["USE_REAL_TIME_DATA"]:
            try:
                today_date = datetime.datetime.now().date()
                if is_trade_day(today_date):
                    df_spot = fetch_realtime_snapshot()
                    if df_spot.empty:
                        print("[ç»ˆæ­¢] æ— æ³•è·å–å®æ—¶è¡Œæƒ…å¿«ç…§ï¼Œç»ˆæ­¢æ‰«æã€‚")
                        sys.exit(1)
                else:
                    print("[é…ç½®] å½“å‰ä¸ºéäº¤æ˜“æ—¥ï¼Œè·³è¿‡å®æ—¶å¿«ç…§è·å–ã€‚")
            except Exception as e:
                print(f"[è‡´å‘½ç»ˆæ­¢] è·å–å®æ—¶è¡Œæƒ…å¿«ç…§å¤±è´¥: {e}")
                sys.exit(1)
        else:
            print("[é…ç½®] å®æ—¶æ•°æ®è·å–å¼€å…³å…³é—­ (USE_REAL_TIME_DATA=False)ï¼Œè·³è¿‡å…¨å¸‚åœºå¿«ç…§è·å–ã€‚")

        manual_list = CONFIG["MANUAL_STOCK_LIST"]
        df_base = pd.DataFrame()
        target_codes = []

        if manual_list and len(manual_list) > 0:
            target_codes = [str(c).zfill(6) for c in manual_list]
            print(f"[æ‰‹åŠ¨æ¨¡å¼] ä½¿ç”¨æ‰‹åŠ¨è¾“å…¥åˆ—è¡¨ï¼Œå…± {len(target_codes)} æ”¯è‚¡ç¥¨ã€‚")
            try:
                df_base = get_stock_list_manager()
            except Exception:
                df_base = pd.DataFrame({"code": target_codes, "name": ["æœªçŸ¥"] * len(target_codes)})
        else:
            try:
                df_base = get_stock_list_manager()
            except Exception as e:
                print(f"[ç»ˆæ­¢] æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨: {e}")
                return
            valid_codes = filter_stock_list(df_base)
            sample_size = CONFIG["SAMPLE_SIZE"]
            if isinstance(sample_size, int) and sample_size > 0 and len(valid_codes) > sample_size:
                print(f"[æŠ½æ ·æ¨¡å¼] éšæœºæŠ½å– {sample_size} æ”¯è‚¡ç¥¨è¿›è¡Œæµ‹è¯•...")
                target_codes = random.sample(valid_codes, sample_size)
            else:
                print(f"[å…¨é‡æ¨¡å¼] æ‰«ææ‰€æœ‰ {len(valid_codes)} æ”¯æœ‰æ•ˆè‚¡ç¥¨...")
                target_codes = valid_codes

        if CONFIG["SAMPLE_SIZE"] > 0 or len(target_codes) <= CONFIG["BATCH_SIZE"]:
            final_data = asyncio.run(main_scanner_async(target_codes, df_spot))
        else:
            final_data = asyncio.run(batch_scan_manager_async(target_codes, df_spot))

        # 4. ç»“æœæ•´ç†ä¸å¯¼å‡º
        if final_data:
            res_df = pd.DataFrame(final_data)

            name_map = df_base.set_index('code')['name'].to_dict()
            res_df['åç§°'] = res_df['ä»£ç '].map(name_map).fillna('æœªçŸ¥')

            today_date_str = datetime.datetime.now().strftime('%Y-%m-%d')
            folder_path = os.path.join(CONFIG["OUTPUT_FOLDER_BASE"], today_date_str)
            os.makedirs(folder_path, exist_ok=True)
            timestamp = datetime.datetime.now().strftime('%H%M%S')
            file_name = f"{CONFIG['OUTPUT_FILENAME_BASE']}_{timestamp}.csv"
            full_file_path = os.path.join(folder_path, file_name)

            # é‡æ–°æ’åºç»“æœåˆ— (æ–°å¢ EMA20, ä¿¡å·ç­‰çº§, DIç›¸å¯¹å¼ºåº¦)
            ordered_cols = [
                "æ—¥æœŸ", "ä»£ç ", "åç§°", "ä¿¡å·ç­‰çº§", "è¶‹åŠ¿è¿‡æ»¤",
                "å½“å‰ä»·", "æ¶¨å¹…%",
                "StochK", "StochD", "EMA20", "EMA50", "EMA200",
                "ADX", "DI+", "DI-", "DIç›¸å¯¹å¼º", "ADXä¿¡å·",
                "ATR", "æ­¢æŸä»·", "æ­¢ç›ˆä»·",
            ]

            # ç¡®ä¿åªåŒ…å«å®é™…å­˜åœ¨çš„åˆ—
            ordered_cols = [col for col in ordered_cols if col in res_df.columns]
            res_df = res_df[ordered_cols]

            res_df = res_df.sort_values(["æ¶¨å¹…%"], ascending=[False]).reset_index(drop=True)

            res_df.to_csv(full_file_path, index=False, encoding=CONFIG["EXPORT_ENCODING"])

            print("\n" + "=" * 60)
            print(f"âœ… æ‰«æå®Œæˆ | è€—æ—¶: {time.time() - start_time:.1f}s")
            print(f"ğŸ“„ ç»“æœæ–‡ä»¶å·²ä¿å­˜è‡³: {full_file_path}")
            print(f"ğŸ“ˆ å‘½ä¸­æ•°é‡: {len(res_df)}")
            print("=" * 60)
            print("--- å‘½ä¸­è‚¡ç¥¨ Top 10 ---")
            print(res_df.head(10).to_string(index=False))
            return res_df

        else:
            print("\n[ç»“æœ] æ²¡æœ‰å‘ç°ç¬¦åˆç­–ç•¥çš„è‚¡ç¥¨ã€‚")
            return pd.DataFrame()


if __name__ == "__main__":
    main()
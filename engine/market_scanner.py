# -*- coding: utf-8 -*-
import asyncio
import time
import os
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from core.data_handler import DataHandler
from conf.config import SYSTEM_CONFIG, PATH_CONFIG
from strategies.breakout_strategy import run_breakout_strategy


class MarketScanner:
    def __init__(self):
        self.handler = DataHandler()
        self.matched_list = []

    def _worker(self, symbol):
        """
        åŒæ­¥è®¡ç®—é€»è¾‘ï¼Œç”±çº¿ç¨‹æ± é©±åŠ¨

        *** ç­–ç•¥è®¡ç®— ***
        *** ç­–ç•¥è®¡ç®— ***
        *** ç­–ç•¥è®¡ç®— ***
        """
        df = self.handler.get_full_data(symbol)
        # ç¡®ä¿ strategy å†…éƒ¨é€»è¾‘å·²ç»é€‚é…æœ€æ–°çš„å‚æ•°
        return run_breakout_strategy(df, symbol)

    async def run_full_scan(self, symbols=None):
        """å¼‚æ­¥æ‰«æä¸»å…¥å£"""
        if symbols is None:
            symbols = self.handler.get_target_list()

        if not symbols:
            print("âŒ æ‰«æç»ˆæ­¢ï¼šå¾…å¤„ç†åå•ä¸ºç©ºã€‚")
            return

        # 1. é¢„å–å®æ—¶å¿«ç…§ (åŒæ­¥æ–¹æ³•ï¼Œä¸€æ¬¡æ€§æ‹‰å–)
        self.handler.prepare_realtime_data()

        batch_size = SYSTEM_CONFIG.get("BATCH_SIZE", 500)
        batches = list(self.handler.chunk_symbols(symbols, batch_size))
        print(f"âœ… å¼‚æ­¥æ‰«æå°±ç»ªï¼Œå…± {len(symbols)} åªï¼Œåˆ† {len(batches)} æ‰¹ã€‚")

        max_workers = SYSTEM_CONFIG.get("MAX_WORKERS", 10)
        interval = SYSTEM_CONFIG.get("BATCH_INTERVAL_SEC", 1)

        # è·å–å½“å‰å¼‚æ­¥äº‹ä»¶å¾ªç¯
        loop = asyncio.get_running_loop()

        for i, batch in enumerate(batches):
            print(f"\nğŸ“¦ æ‰¹æ¬¡ {i + 1}/{len(batches)} (è§„æ¨¡: {len(batch)})")
            batch_matched = []

            # 2. çº¿ç¨‹æ± é…åˆå¼‚æ­¥ run_in_executor
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
                tasks = [
                    loop.run_in_executor(executor, self._worker, s)
                    for s in batch
                ]

                # ä½¿ç”¨ tqdm é…åˆ as_completed å±•ç¤ºè¿›åº¦
                pbar = tqdm(asyncio.as_completed(tasks),
                            total=len(tasks),
                            desc=f"è¿›åº¦{i + 1}",
                            ncols=80)

                for task in pbar:
                    res = await task  # å¼‚æ­¥ç­‰å¾…çº¿ç¨‹ç»“æœ
                    if res:
                        batch_matched.append(res)
                        pbar.set_postfix({"å‘½ä¸­": len(batch_matched) + len(self.matched_list)})

            self.matched_list.extend(batch_matched)

            # 3. å¼‚æ­¥éé˜»å¡ä¼‘æ¯
            if i < len(batches) - 1 and interval > 0:
                await asyncio.sleep(interval)

        # 4. å¯¼å‡ºç»“æœ
        self.export_results()

    def export_results(self):
        """(ä¿æŒåŸæ ·)"""
        if not self.matched_list:
            print("\nğŸ æ‰«æå®Œæˆï¼Œæœªå‘ç°åŒ¹é…ä¿¡å·ã€‚")
            return
        df_res = pd.DataFrame(self.matched_list)
        date_str = time.strftime('%Y%m%d')
        save_dir = os.path.join(PATH_CONFIG["OUTPUT_FOLDER_BASE"], date_str)
        if not os.path.exists(save_dir): os.makedirs(save_dir)
        file_path = os.path.join(save_dir, f"scan_res_{time.strftime('%H%M%S')}.csv")
        df_res.to_csv(file_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ‰ æ‰«æç»“æŸï¼å‘½ä¸­: {len(self.matched_list)} | æ–‡ä»¶: {file_path}")
# -*- coding: utf-8 -*-
import time
import os
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm  # <--- å¯¼å…¥è¿›åº¦æ¡åº“
from core.data_handler import DataHandler
from indicators.squeeze_momentum_indicator import squeeze_momentum_indicator
from conf.config import SYSTEM_CONFIG, PATH_CONFIG


class MarketScanner:
    def __init__(self):
        self.handler = DataHandler()
        self.matched_list = []

    def _worker(self, symbol):
        """å•åªè‚¡ç¥¨çš„æ‰«æé€»è¾‘"""
        try:
            df = self.handler.get_full_data(symbol)
            if df is None or len(df) < 35:
                return None

            df = squeeze_momentum_indicator(df)
            if df.empty: return None

            last_row = df.iloc[-1]
            prev_row = df.iloc[-2]

            # ç­–ç•¥ä¿¡å·ï¼šSQZé‡Šæ”¾
            if last_row['sqz_status'] == 'OFF' and prev_row['sqz_status'] == 'ON':
                return {
                    "ä»£ç ": symbol,
                    "æœ€æ–°ä»·": last_row['close'],
                    "åŠ¨èƒ½å€¼": round(last_row['sqz_hvalue'], 4),
                    "æ‰«ææ—¶é—´": time.strftime("%H:%M:%S")
                }
        except Exception:
            return None
        return None

    def run_full_scan(self, symbols=None):
        if symbols is None:
            symbols = self.handler.get_target_list()

        if not symbols:
            print("âŒ æ‰«æç»ˆæ­¢ï¼šå¾…å¤„ç†åå•ä¸ºç©ºã€‚")
            return

        # 1. é¢„å–å®æ—¶å¿«ç…§
        self.handler.prepare_realtime_data()

        # 2. åˆ†æ‰¹
        batch_size = SYSTEM_CONFIG.get("BATCH_SIZE", 500)
        batches = list(self.handler.chunk_symbols(symbols, batch_size))

        print(f"âœ… æ‰«æå‡†å¤‡å°±ç»ªï¼Œå…± {len(symbols)} åªï¼Œåˆ†ä¸º {len(batches)} æ‰¹æ¬¡ã€‚")

        max_workers = SYSTEM_CONFIG.get("MAX_WORKERS", 10)
        interval = SYSTEM_CONFIG.get("BATCH_INTERVAL_SEC", 2)

        # 3. æ‰§è¡Œå¤šçº¿ç¨‹å¹¶å‘æ‰«æ
        for i, batch in enumerate(batches):
            print(f"\nğŸ“¦ æ­£åœ¨å¤„ç†ç¬¬ {i + 1}/{len(batches)} æ‰¹ (è§„æ¨¡: {len(batch)})...")

            batch_matched = []

            # ä½¿ç”¨ as_completed é…åˆ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤ä»»åŠ¡
                future_to_symbol = {executor.submit(self._worker, s): s for s in batch}

                # tqdm è£…é¥°å™¨ï¼štotal ä¸ºæœ¬æ‰¹æ¬¡æ€»æ•°ï¼Œdesc ä¸ºè¯´æ˜æ–‡å­—ï¼Œleave=False ç»“æŸåè‡ªåŠ¨æ¸…ç†
                pbar = tqdm(as_completed(future_to_symbol),
                            total=len(batch),
                            desc=f"æ‰¹æ¬¡{i + 1}è¿›åº¦",
                            unit="stock",
                            ncols=80)

                for future in pbar:
                    res = future.result()
                    if res:
                        batch_matched.append(res)
                        # åœ¨è¿›åº¦æ¡å³ä¾§åŠ¨æ€æ˜¾ç¤ºå‘½ä¸­æ•°é‡
                        pbar.set_postfix({"å‘½ä¸­": len(batch_matched) + len(self.matched_list)})

            self.matched_list.extend(batch_matched)

            # æ‰¹æ¬¡é—´éš”
            if i < len(batches) - 1 and interval > 0:
                time.sleep(interval)

        # 4. å¯¼å‡ºç»“æœ
        self.export_results()

    def export_results(self):
        # ... (ä¿æŒä¹‹å‰çš„å¯¼å‡ºä»£ç ä¸å˜)
        if not self.matched_list:
            print("\nğŸ æ‰«æå®Œæˆï¼Œæœªå‘ç°åŒ¹é…ä¿¡å·ã€‚")
            return

        df_res = pd.DataFrame(self.matched_list)
        date_str = time.strftime('%Y%m%d')
        save_dir = os.path.join(PATH_CONFIG["OUTPUT_FOLDER_BASE"], date_str)
        if not os.path.exists(save_dir): os.makedirs(save_dir)
        file_path = os.path.join(save_dir, f"scan_res_{time.strftime('%H%M%S')}.csv")
        df_res.to_csv(file_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ‰ æ‰«æç»“æŸï¼å‘ç°ä¿¡å·: {len(self.matched_list)} æ¡ | å­˜è‡³: {file_path}")